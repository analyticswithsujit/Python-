{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1c3429-52b8-44a9-b7af-da7b3dc8648a",
   "metadata": {},
   "source": [
    "##  Objective\n",
    "The objective of this assignment is to extract textual data from the given URLs, perform sentiment and readability analysis, and produce the required output as per the given structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc034e93-0162-4ed1-88f2-521b42d3debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# Download NLTK punkt tokenizer (needed for sentence splitting)\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5108ea97-46f0-41ad-bbe2-147db61f0a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Acer\\BLACKCOFFER\n",
      "Files available: ['.ipynb_checkpoints', 'Input.xlsx', 'negative-words.txt', 'Objective.docx', 'Output Data Structure.xlsx', 'positive-words.txt', 'StopWords_Auditor.txt', 'StopWords_Currencies.txt', 'StopWords_DatesandNumbers.txt', 'StopWords_Generic.txt', 'StopWords_GenericLong.txt', 'StopWords_Geographic.txt', 'StopWords_Names.txt', 'Text Analysis.docx', 'Untitled.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# os.chdir(\"BLACKCOFFER\")   # REMOVE or COMMENT OUT\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "print(\"Files available:\", os.listdir())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402ad74d-37ec-4ece-8075-2bc04ebf608d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total StopWords Loaded: 12768\n"
     ]
    }
   ],
   "source": [
    "stopwords = set()\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file.startswith(\"StopWords\") and file.endswith(\".txt\"):\n",
    "        with open(file, \"r\", encoding=\"latin-1\") as f:\n",
    "            for word in f:\n",
    "                stopwords.add(word.strip().lower())\n",
    "\n",
    "print(\"✅ Total StopWords Loaded:\", len(stopwords))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b8da2f-f3b6-42ab-aec4-2943e9b33d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Positive Words: 2006\n",
      "✅ Negative Words: 4783\n"
     ]
    }
   ],
   "source": [
    "with open(\"positive-words.txt\", \"r\", encoding=\"latin-1\") as f:\n",
    "    positive_words = [line.strip().lower() for line in f if line.strip()]\n",
    "\n",
    "with open(\"negative-words.txt\", \"r\", encoding=\"latin-1\") as f:\n",
    "    negative_words = [line.strip().lower() for line in f if line.strip()]\n",
    "\n",
    "print(\"✅ Positive Words:\", len(positive_words))\n",
    "print(\"✅ Negative Words:\", len(negative_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d25857-d6e4-4ed8-a439-0c4719b8a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text).lower())\n",
    "    words = [w for w in text.split() if w not in stopwords]\n",
    "    return words\n",
    "\n",
    "def syllable_count(word):\n",
    "    vowels = \"aeiou\"\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    if word and word[0] in vowels:\n",
    "        count += 1\n",
    "    for i in range(1, len(word)):\n",
    "        if word[i] in vowels and word[i-1] not in vowels:\n",
    "            count += 1\n",
    "    if word.endswith((\"es\",\"ed\")):\n",
    "        count -= 1\n",
    "    return max(1, count)\n",
    "\n",
    "def extract_article(url):\n",
    "    try:\n",
    "        page = requests.get(url, timeout=10)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        paragraphs = [p.get_text() for p in soup.find_all(\"p\")]\n",
    "        return \" \".join(paragraphs)\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def analyze_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    words = clean_text(text)\n",
    "\n",
    "    pos_score = sum(1 for w in words if w in positive_words)\n",
    "    neg_score = sum(1 for w in words if w in negative_words)\n",
    "\n",
    "    polarity = (pos_score - neg_score) / ((pos_score + neg_score) + 1e-6)\n",
    "    subjectivity = (pos_score + neg_score) / (len(words) + 1e-6)\n",
    "\n",
    "    word_count = len(words)\n",
    "    sentence_count = len(sentences) if sentences else 1\n",
    "    avg_sentence_length = word_count / sentence_count\n",
    "\n",
    "    complex_words = [w for w in words if syllable_count(w) > 2]\n",
    "    complex_count = len(complex_words)\n",
    "    pct_complex = complex_count / (word_count + 1e-6)\n",
    "    fog_index = 0.4 * (avg_sentence_length + pct_complex)\n",
    "\n",
    "    syllables_per_word = sum(syllable_count(w) for w in words) / (word_count + 1e-6)\n",
    "    avg_word_len = sum(len(w) for w in words) / (word_count + 1e-6)\n",
    "    pronouns = len(re.findall(r\"\\b(I|we|my|ours|us)\\b\", text, re.I))\n",
    "\n",
    "    return {\n",
    "        \"POSITIVE SCORE\": pos_score,\n",
    "        \"NEGATIVE SCORE\": neg_score,\n",
    "        \"POLARITY SCORE\": polarity,\n",
    "        \"SUBJECTIVITY SCORE\": subjectivity,\n",
    "        \"AVG SENTENCE LENGTH\": avg_sentence_length,\n",
    "        \"PERCENTAGE OF COMPLEX WORDS\": pct_complex,\n",
    "        \"FOG INDEX\": fog_index,\n",
    "        \"AVG NUMBER OF WORDS PER SENTENCE\": avg_sentence_length,\n",
    "        \"COMPLEX WORD COUNT\": complex_count,\n",
    "        \"WORD COUNT\": word_count,\n",
    "        \"SYLLABLE PER WORD\": syllables_per_word,\n",
    "        \"PERSONAL PRONOUNS\": pronouns,\n",
    "        \"AVG WORD LENGTH\": avg_word_len\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1476e0e-bf23-47ff-a441-15acd1138d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Input File Loaded: 147 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...\n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...\n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...\n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...\n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Input.xlsx\")\n",
    "print(\"✅ Input File Loaded:\", df.shape[0], \"rows\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297ac62a-77a5-4047-b1c7-324703456dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc3f46aa-e191-446b-9248-79c0376dd2ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/147: https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "Processing 2/147: https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "Processing 3/147: https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "Processing 4/147: https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "Processing 5/147: https://insights.blackcoffer.com/development-of-ea-robot-for-automated-trading/\n",
      "Processing 6/147: https://insights.blackcoffer.com/ai-and-ml-based-youtube-analytics-and-content-creation-tool-for-optimizing-subscriber-engagement-and-content-strategy/\n",
      "Processing 7/147: https://insights.blackcoffer.com/enhancing-front-end-features-and-functionality-for-improved-user-experience-and-dashboard-accuracy-in-partner-hospital-application/\n",
      "Processing 8/147: https://insights.blackcoffer.com/roas-dashboard-for-campaign-wise-google-ads-budget-tracking-using-google-ads-ap/\n",
      "Processing 9/147: https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/\n",
      "Processing 10/147: https://insights.blackcoffer.com/transforming-and-managing-a-large-scale-sql-pedigree-database-to-neo4j-graph-db/\n",
      "Processing 11/147: https://insights.blackcoffer.com/enhancing-model-accuracy-from-58-to-over-90-strategies-for-improving-predictive-performance/\n",
      "Processing 12/147: https://insights.blackcoffer.com/securing-sensitive-financial-data-with-privacy-preserving-machine-learning-for-predictive-analytics/\n",
      "Processing 13/147: https://insights.blackcoffer.com/enhancing-data-collection-for-research-institutions-addressing-survey-fatigue-and-incorporating-verbal-communication-for-richer-insights/\n",
      "Processing 14/147: https://insights.blackcoffer.com/analyzing-the-impact-of-positive-emotions-and-pandemic-severity-on-mental-health-and-resilience-among-entrepreneurs-insights-and-predictive-modeling/\n",
      "Processing 15/147: https://insights.blackcoffer.com/dynamic-brand-centric-dashboard-for-automotive-dealerships-pdf-to-financial-insights-with-flask-react-architecture-and-aws-cloud-hosting/\n",
      "Processing 16/147: https://insights.blackcoffer.com/cloud-based-data-modeling-and-analysis-platform-with-drag-and-drop-interface-and-openai-api-integration-for-simulation-insights/\n",
      "Processing 17/147: https://insights.blackcoffer.com/voter-profile-analysis-and-search-application-for-targeted-campaign-engagement-using-government-voter-data/\n",
      "Processing 18/147: https://insights.blackcoffer.com/bert-based-classification-of-individuals-and-organizations-into-two-categories-using-natural-language-processing/\n",
      "Processing 19/147: https://insights.blackcoffer.com/comprehensive-analysis-of-solana-and-ethereum-contributors-using-github-api-with-comparative-study-of-1000-random-github-profiles/\n",
      "Processing 20/147: https://insights.blackcoffer.com/powerbi-rest-api-fetching-dataflow-and-refresh-schedules-with-semantic-models/\n",
      "Processing 21/147: https://insights.blackcoffer.com/automated-job-data-import-and-management-solution-for-enhanced-efficiency/\n",
      "Processing 22/147: https://insights.blackcoffer.com/data-analytics-and-optimization-solution-for-enhancing-renewable-energy-efficiency/\n",
      "Processing 23/147: https://insights.blackcoffer.com/time-series-analysis-and-trend-forecasting-solution-for-predicting-news-trends/\n",
      "Processing 24/147: https://insights.blackcoffer.com/advanced-data-visualization-solutions-for-monitoring-key-business-metrics-with-integrated-interactive-dashboards/\n",
      "Processing 25/147: https://insights.blackcoffer.com/advanced-patient-data-analysis-solution-for-trend-identification-and-improved-healthcare-outcome/\n",
      "Processing 26/147: https://insights.blackcoffer.com/anomaly-detection-and-analysis-for-enhanced-data-integrity-and-user-experience-on-bright-datas-website/\n",
      "Processing 27/147: https://insights.blackcoffer.com/building-custom-tflite-models-and-benchmarking-on-voxl2-chips/\n",
      "Processing 28/147: https://insights.blackcoffer.com/sports-prediction-model-for-multiple-sports-leagues/\n",
      "Processing 29/147: https://insights.blackcoffer.com/efficient-coach-allocation-system-for-sports-coaching-organization/\n",
      "Processing 30/147: https://insights.blackcoffer.com/data-studio-dashboard-with-a-data-pipeline-tool-synced-with-podio-using-custom-webhooks-and-google-cloud-function-2/\n",
      "Processing 31/147: https://insights.blackcoffer.com/ai-driven-backend-for-audio-to-text-conversion-and-analytical-assessment-in-pharmaceutical-practice/\n",
      "Processing 32/147: https://insights.blackcoffer.com/cloud-based-web-application-for-financial-data-processing-and-visualization-of-sp-500-metrics/\n",
      "Processing 33/147: https://insights.blackcoffer.com/department-wise-kpi-tracking-dashboard-with-technician-performance-analysis-for-atoz-dependable-service/\n",
      "Processing 34/147: https://insights.blackcoffer.com/steps-to-convert-a-node-js-api-to-python-for-aws-lambda-deployment/\n",
      "Processing 35/147: https://insights.blackcoffer.com/building-an-analytics-dashboard-with-a-pdf-parsing-pipeline-for-data-extraction/\n",
      "Processing 36/147: https://insights.blackcoffer.com/building-a-real-time-log-file-visualization-dashboard-in-kibana/\n",
      "Processing 37/147: https://insights.blackcoffer.com/analyzing-the-impact-of-female-ceo-appointments-on-company-stock-prices/\n",
      "Processing 38/147: https://insights.blackcoffer.com/ai-chatbot-using-llm-langchain-llama/\n",
      "Processing 39/147: https://insights.blackcoffer.com/healthcare-ai-chatbot-using-llama-llm-langchain/\n",
      "Processing 40/147: https://insights.blackcoffer.com/ai-bot-audio-to-audio/\n",
      "Processing 41/147: https://insights.blackcoffer.com/recommendation-engine-for-insurance-sector-to-expand-business-in-the-rural-area/\n",
      "Processing 42/147: https://insights.blackcoffer.com/data-from-crm-via-zapier-to-google-sheets-dynamic-to-powerbi/\n",
      "Processing 43/147: https://insights.blackcoffer.com/data-warehouse-to-google-data-studio-looker-dashboard/\n",
      "Processing 44/147: https://insights.blackcoffer.com/crm-monday-com-via-zapier-to-power-bi-dashboard/\n",
      "Processing 45/147: https://insights.blackcoffer.com/monday-com-to-kpi-dashboard-to-manage-view-and-generate-insights-from-the-crm-data/\n",
      "Processing 46/147: https://insights.blackcoffer.com/data-management-for-a-political-saas-application/\n",
      "Processing 47/147: https://insights.blackcoffer.com/google-lsa-ads-google-local-service-ads-etl-tools-and-dashboards/\n",
      "Processing 48/147: https://insights.blackcoffer.com/ad-networks-marketing-campaign-data-dashboard-in-looker-google-data-studio/\n",
      "Processing 49/147: https://insights.blackcoffer.com/analytical-solution-for-a-tech-firm/\n",
      "Processing 50/147: https://insights.blackcoffer.com/ai-solution-for-a-technology-information-and-internet-firm/\n",
      "Processing 51/147: https://insights.blackcoffer.com/ai-and-nlp-based-solutions-to-automate-data-discovery-for-venture-capital-and-private-equity-principals/\n",
      "Processing 52/147: https://insights.blackcoffer.com/an-etl-solution-for-an-internet-publishing-firm/\n",
      "Processing 53/147: https://insights.blackcoffer.com/ai-based-algorithmic-trading-bot-for-forex/\n",
      "Processing 54/147: https://insights.blackcoffer.com/equity-waterfalls-model-based-saas-application-for-real-estate-sector/\n",
      "Processing 55/147: https://insights.blackcoffer.com/ai-solutions-for-foreign-exchange-an-automated-algo-trading-tool/\n",
      "Processing 56/147: https://insights.blackcoffer.com/ai-agent-development-and-deployment-in-jina-ai/\n",
      "Processing 57/147: https://insights.blackcoffer.com/golden-record-a-knowledge-graph-database-approach-to-unfold-discovery-using-neo4j/\n",
      "Processing 58/147: https://insights.blackcoffer.com/advanced-ai-for-trading-automation/\n",
      "Processing 59/147: https://insights.blackcoffer.com/create-a-knowledge-graph-to-provide-real-time-analytics-recommendations-and-a-single-source-of-truth/\n",
      "Processing 60/147: https://insights.blackcoffer.com/advanced-ai-for-thermal-person-detection/\n",
      "Processing 61/147: https://insights.blackcoffer.com/advanced-ai-for-road-cam-threat-detection/\n",
      "Processing 62/147: https://insights.blackcoffer.com/advanced-ai-for-pedestrian-crossing-safety/\n",
      "Processing 63/147: https://insights.blackcoffer.com/handgun-detection-using-yolo/\n",
      "Processing 64/147: https://insights.blackcoffer.com/using-graph-technology-to-create-single-customer-view/\n",
      "Processing 65/147: https://insights.blackcoffer.com/car-detection-in-satellite-images/\n",
      "Processing 66/147: https://insights.blackcoffer.com/building-a-physics-informed-neural-network-for-circuit-evaluation/\n",
      "Processing 67/147: https://insights.blackcoffer.com/connecting-mongodb-database-to-power-bi-dashboard-dashboard-automation/\n",
      "Processing 68/147: https://insights.blackcoffer.com/data-transformation/\n",
      "Processing 69/147: https://insights.blackcoffer.com/e-commerce-store-analysis-purchase-behavior-ad-spend-conversion-traffic-etc/\n",
      "Processing 70/147: https://insights.blackcoffer.com/kpi-dashboard-for-accountants/\n",
      "Processing 71/147: https://insights.blackcoffer.com/return-on-advertising-spend-dashboard-marketing-automation-and-analytics-using-etl-and-dashboard/\n",
      "Processing 72/147: https://insights.blackcoffer.com/ranking-customer-behaviours-for-business-strategy/\n",
      "Processing 73/147: https://insights.blackcoffer.com/algorithmic-trading-for-multiple-commodities-markets-like-forex-metals-energy-etc/\n",
      "Processing 74/147: https://insights.blackcoffer.com/trading-bot-for-forex/\n",
      "Processing 75/147: https://insights.blackcoffer.com/python-model-for-the-analysis-of-sector-specific-stock-etfs-for-investment-purposes%ef%bf%bc/\n",
      "Processing 76/147: https://insights.blackcoffer.com/medical-classification/\n",
      "Processing 77/147: https://insights.blackcoffer.com/design-develop-bert-question-answering-model-explanations-with-visualization/\n",
      "Processing 78/147: https://insights.blackcoffer.com/design-and-develop-solution-to-anomaly-detection-classification-problems/\n",
      "Processing 79/147: https://insights.blackcoffer.com/an-etl-solution-for-currency-data-to-google-big-query/\n",
      "Processing 80/147: https://insights.blackcoffer.com/etl-and-mlops-infrastructure-for-blockchain-analytics/\n",
      "Processing 81/147: https://insights.blackcoffer.com/an-agent-based-model-of-a-virtual-power-plant-vpp/\n",
      "Processing 82/147: https://insights.blackcoffer.com/transform-api-into-sdk-library-and-widget/\n",
      "Processing 83/147: https://insights.blackcoffer.com/integration-of-a-product-to-a-cloud-based-crm-platform/\n",
      "Processing 84/147: https://insights.blackcoffer.com/a-web-based-dashboard-for-the-filtered-data-retrieval-of-land-records/\n",
      "Processing 85/147: https://insights.blackcoffer.com/integration-of-video-conferencing-data-to-the-existing-web-app/\n",
      "Processing 86/147: https://insights.blackcoffer.com/design-develop-an-app-in-retool-which-shows-the-progress-of-the-added-video/\n",
      "Processing 87/147: https://insights.blackcoffer.com/auvik-connectwise-integration-in-grafana/\n",
      "Processing 88/147: https://insights.blackcoffer.com/data-integration-and-big-data-performance-using-elk-stack/\n",
      "Processing 89/147: https://insights.blackcoffer.com/web-data-connector/\n",
      "Processing 90/147: https://insights.blackcoffer.com/an-app-for-updating-the-email-id-of-the-user-and-stripe-refund-tool-using-retool/\n",
      "Processing 91/147: https://insights.blackcoffer.com/an-ai-ml-based-web-application-that-detects-the-correctness-of-text-in-a-given-video/\n",
      "Processing 92/147: https://insights.blackcoffer.com/website-tracking-and-insights-using-google-analytics-google-tag-manager/\n",
      "Processing 93/147: https://insights.blackcoffer.com/dashboard-to-track-the-analytics-of-the-website-using-google-analytics-and-google-tag-manager/\n",
      "Processing 94/147: https://insights.blackcoffer.com/power-bi-dashboard-on-operations-transactions-and-marketing-embedding-the-dashboard-to-web-app/\n",
      "Processing 95/147: https://insights.blackcoffer.com/nft-data-automation-looksrare-and-etl-tool/\n",
      "Processing 96/147: https://insights.blackcoffer.com/optimize-the-data-scraper-program-to-easily-accommodate-large-files-and-solve-oom-errors/\n",
      "Processing 97/147: https://insights.blackcoffer.com/making-a-robust-way-to-sync-data-from-airtables-to-mongodb-using-python-etl-solution/\n",
      "Processing 98/147: https://insights.blackcoffer.com/incident-duration-prediction-infrastructure-and-real-estate/\n",
      "Processing 99/147: https://insights.blackcoffer.com/statistical-data-analysis-of-reinforced-concrete/\n",
      "Processing 100/147: https://insights.blackcoffer.com/database-normalization-segmentation-with-google-data-studio-dashboard-insights/\n",
      "Processing 101/147: https://insights.blackcoffer.com/power-bi-dashboard-to-drive-insights-from-complex-data-to-generate-business-insights/\n",
      "Processing 102/147: https://insights.blackcoffer.com/real-time-dashboard-to-monitor-infrastructure-activity-and-machines/\n",
      "Processing 103/147: https://insights.blackcoffer.com/electric-vehicles-ev-load-management-system-to-forecast-energy-demand/\n",
      "Processing 104/147: https://insights.blackcoffer.com/power-bi-data-driven-map-dashboard/\n",
      "Processing 105/147: https://insights.blackcoffer.com/google-local-service-ads-lsa-leads-dashboard/\n",
      "Processing 106/147: https://insights.blackcoffer.com/aws-lex-voice-and-chatbot/\n",
      "Processing 107/147: https://insights.blackcoffer.com/metabridges-api-decentraland-integration/\n",
      "Processing 108/147: https://insights.blackcoffer.com/microsoft-azure-chatbot-with-luis-language-understanding/\n",
      "Processing 109/147: https://insights.blackcoffer.com/impact-of-news-media-and-press-on-innovation-startups-and-investments/\n",
      "Processing 110/147: https://insights.blackcoffer.com/aws-quicksight-reporting-dashboard/\n",
      "Processing 111/147: https://insights.blackcoffer.com/google-data-studio-dashboard-for-marketing-ads-and-traction-data/\n",
      "Processing 112/147: https://insights.blackcoffer.com/gangala-in-e-commerce-big-data-etl-elt-solution-and-data-warehouse/\n",
      "Processing 113/147: https://insights.blackcoffer.com/big-data-solution-to-an-online-multivendor-marketplace-ecommerce-business/\n",
      "Processing 114/147: https://insights.blackcoffer.com/creating-a-custom-report-and-dashboard-using-the-data-got-from-atera-api/\n",
      "Processing 115/147: https://insights.blackcoffer.com/azure-data-lake-and-power-bi-dashboard/\n",
      "Processing 116/147: https://insights.blackcoffer.com/google-data-studio-pipeline-with-gcp-mysql/\n",
      "Processing 117/147: https://insights.blackcoffer.com/quickbooks-dashboard-to-find-patterns-in-finance-sales-and-forecasts/\n",
      "Processing 118/147: https://insights.blackcoffer.com/marketing-sales-and-financial-data-business-dashboard-wink-report/\n",
      "Processing 119/147: https://insights.blackcoffer.com/react-native-apps-in-the-development-portfolio/\n",
      "Processing 120/147: https://insights.blackcoffer.com/a-leading-firm-website-seo-optimization/\n",
      "Processing 121/147: https://insights.blackcoffer.com/a-leading-hospitality-firm-in-the-usa-website-seo-optimization/\n",
      "Processing 122/147: https://insights.blackcoffer.com/a-leading-firm-in-the-usa-website-seo-optimization/\n",
      "Processing 123/147: https://insights.blackcoffer.com/a-leading-musical-instrumental-website-seo-optimization/\n",
      "Processing 124/147: https://insights.blackcoffer.com/a-leading-firm-in-the-usa-seo-and-website-optimization/\n",
      "Processing 125/147: https://insights.blackcoffer.com/immigration-datawarehouse-ai-based-recommendations/\n",
      "Processing 126/147: https://insights.blackcoffer.com/lipsync-automation-for-celebrities-and-influencers/\n",
      "Processing 127/147: https://insights.blackcoffer.com/key-audit-matters-predictive-modeling/\n",
      "Processing 128/147: https://insights.blackcoffer.com/splitting-of-songs-into-its-vocals-and-instrumental/\n",
      "Processing 129/147: https://insights.blackcoffer.com/ai-and-ml-technologies-to-evaluate-learning-assessments/\n",
      "Processing 130/147: https://insights.blackcoffer.com/datawarehouse-and-recommendations-engine-for-airbnb/\n",
      "Processing 131/147: https://insights.blackcoffer.com/real-estate-data-warehouse/\n",
      "Processing 132/147: https://insights.blackcoffer.com/traction-dashboards-of-marketing-campaigns-and-posts/\n",
      "Processing 133/147: https://insights.blackcoffer.com/google-local-service-ads-lsa-data-warehouse/\n",
      "Processing 134/147: https://insights.blackcoffer.com/google-local-service-ads-missed-calls-and-messages-automation-tool/\n",
      "Processing 135/147: https://insights.blackcoffer.com/marketing-ads-leads-call-status-data-tool-to-bigquery/\n",
      "Processing 136/147: https://insights.blackcoffer.com/marketing-analytics-to-automate-leads-call-status-and-reporting/\n",
      "Processing 137/147: https://insights.blackcoffer.com/callrail-analytics-leads-report-alert/\n",
      "Processing 138/147: https://insights.blackcoffer.com/marketing-automation-tool-to-notify-lead-details-to-clients-over-email-and-phone/\n",
      "Processing 139/147: https://insights.blackcoffer.com/data-etl-local-service-ads-leads-to-bigquery/\n",
      "Processing 140/147: https://insights.blackcoffer.com/marbles-stimulation-using-python/\n",
      "Processing 141/147: https://insights.blackcoffer.com/stocktwits-data-structurization/\n",
      "Processing 142/147: https://insights.blackcoffer.com/sentimental-analysis-on-shareholder-letter-of-companies/\n",
      "Processing 143/147: https://insights.blackcoffer.com/population-and-community-survey-of-america/\n",
      "Processing 144/147: https://insights.blackcoffer.com/google-lsa-api-data-automation-and-dashboarding/\n",
      "Processing 145/147: https://insights.blackcoffer.com/healthcare-data-analysis/\n",
      "Processing 146/147: https://insights.blackcoffer.com/budget-sales-kpi-dashboard-using-power-bi/\n",
      "Processing 147/147: https://insights.blackcoffer.com/amazon-buy-bot-an-automation-ai-tool-to-auto-checkouts/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.039823</td>\n",
       "      <td>25.111111</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>10.251524</td>\n",
       "      <td>25.111111</td>\n",
       "      <td>117</td>\n",
       "      <td>226</td>\n",
       "      <td>2.685841</td>\n",
       "      <td>3</td>\n",
       "      <td>8.230088</td>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.039256</td>\n",
       "      <td>12.410256</td>\n",
       "      <td>0.402893</td>\n",
       "      <td>5.125260</td>\n",
       "      <td>12.410256</td>\n",
       "      <td>195</td>\n",
       "      <td>484</td>\n",
       "      <td>2.429752</td>\n",
       "      <td>9</td>\n",
       "      <td>7.483471</td>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>23.909091</td>\n",
       "      <td>0.452471</td>\n",
       "      <td>9.744625</td>\n",
       "      <td>23.909091</td>\n",
       "      <td>119</td>\n",
       "      <td>263</td>\n",
       "      <td>2.604563</td>\n",
       "      <td>3</td>\n",
       "      <td>7.912547</td>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.075789</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>0.549474</td>\n",
       "      <td>6.553123</td>\n",
       "      <td>15.833333</td>\n",
       "      <td>261</td>\n",
       "      <td>475</td>\n",
       "      <td>2.692632</td>\n",
       "      <td>6</td>\n",
       "      <td>8.160000</td>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0               9               0        1.000000            0.039823   \n",
       "1              12               7        0.263158            0.039256   \n",
       "2              14               2        0.750000            0.060837   \n",
       "3              26              10        0.444444            0.075789   \n",
       "4               0               0        0.000000            0.000000   \n",
       "\n",
       "   AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0            25.111111                     0.517699  10.251524   \n",
       "1            12.410256                     0.402893   5.125260   \n",
       "2            23.909091                     0.452471   9.744625   \n",
       "3            15.833333                     0.549474   6.553123   \n",
       "4             0.000000                     0.000000   0.000000   \n",
       "\n",
       "   AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                         25.111111                 117         226   \n",
       "1                         12.410256                 195         484   \n",
       "2                         23.909091                 119         263   \n",
       "3                         15.833333                 261         475   \n",
       "4                          0.000000                   0           0   \n",
       "\n",
       "   SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH           URL_ID  \\\n",
       "0           2.685841                  3         8.230088  Netclan20241017   \n",
       "1           2.429752                  9         7.483471  Netclan20241018   \n",
       "2           2.604563                  3         7.912547  Netclan20241019   \n",
       "3           2.692632                  6         8.160000  Netclan20241020   \n",
       "4           0.000000                  0         0.000000  Netclan20241021   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://insights.blackcoffer.com/ai-and-ml-bas...  \n",
       "1  https://insights.blackcoffer.com/enhancing-fro...  \n",
       "2  https://insights.blackcoffer.com/roas-dashboar...  \n",
       "3  https://insights.blackcoffer.com/efficient-pro...  \n",
       "4  https://insights.blackcoffer.com/development-o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Processing {idx+1}/{len(df)}: {row['URL']}\")\n",
    "    text = extract_article(row[\"URL\"])\n",
    "    metrics = analyze_text(text)\n",
    "    metrics[\"URL_ID\"] = row[\"URL_ID\"]\n",
    "    metrics[\"URL\"] = row[\"URL\"]\n",
    "    results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8a0795f-54b9-479a-b0b3-ac342475dcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Output Saved: Final_Output.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_template = pd.read_excel(\"Output Data Structure.xlsx\")\n",
    "\n",
    "for col in results_df.columns:\n",
    "    if col in output_template.columns:\n",
    "        output_template[col] = results_df[col]\n",
    "\n",
    "output_template.to_excel(\"Final_Output.xlsx\", index=False)\n",
    "print(\"✅ Final Output Saved: Final_Output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670b98b7-f3de-4846-a8d8-5a5b5e646b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving article for URL_ID Netclan20241017\n",
      "Saving article for URL_ID Netclan20241018\n",
      "Saving article for URL_ID Netclan20241019\n",
      "Saving article for URL_ID Netclan20241020\n",
      "Saving article for URL_ID Netclan20241021\n",
      "Saving article for URL_ID Netclan20241022\n",
      "Saving article for URL_ID Netclan20241023\n",
      "Saving article for URL_ID Netclan20241024\n",
      "Saving article for URL_ID Netclan20241025\n",
      "Saving article for URL_ID Netclan20241026\n",
      "Saving article for URL_ID Netclan20241027\n",
      "Saving article for URL_ID Netclan20241028\n",
      "Saving article for URL_ID Netclan20241029\n",
      "Saving article for URL_ID Netclan20241030\n",
      "Saving article for URL_ID Netclan20241031\n",
      "Saving article for URL_ID Netclan20241032\n",
      "Saving article for URL_ID Netclan20241033\n",
      "Saving article for URL_ID Netclan20241034\n",
      "Saving article for URL_ID Netclan20241035\n",
      "Saving article for URL_ID Netclan20241036\n",
      "Saving article for URL_ID Netclan20241037\n",
      "Saving article for URL_ID Netclan20241038\n",
      "Saving article for URL_ID Netclan20241039\n",
      "Saving article for URL_ID Netclan20241040\n",
      "Saving article for URL_ID Netclan20241041\n",
      "Saving article for URL_ID Netclan20241042\n",
      "Saving article for URL_ID Netclan20241043\n",
      "Saving article for URL_ID Netclan20241044\n",
      "Saving article for URL_ID Netclan20241045\n",
      "Saving article for URL_ID Netclan20241046\n",
      "Saving article for URL_ID Netclan20241047\n",
      "Saving article for URL_ID Netclan20241048\n",
      "Saving article for URL_ID Netclan20241049\n",
      "Saving article for URL_ID Netclan20241050\n",
      "Saving article for URL_ID Netclan20241051\n",
      "Saving article for URL_ID Netclan20241052\n",
      "Saving article for URL_ID Netclan20241053\n",
      "Saving article for URL_ID Netclan20241054\n",
      "Saving article for URL_ID Netclan20241055\n",
      "Saving article for URL_ID Netclan20241056\n",
      "Saving article for URL_ID Netclan20241057\n",
      "Saving article for URL_ID Netclan20241058\n",
      "Saving article for URL_ID Netclan20241059\n",
      "Saving article for URL_ID Netclan20241060\n",
      "Saving article for URL_ID Netclan20241061\n",
      "Saving article for URL_ID Netclan20241062\n",
      "Saving article for URL_ID Netclan20241063\n",
      "Saving article for URL_ID Netclan20241064\n",
      "Saving article for URL_ID Netclan20241065\n",
      "Saving article for URL_ID Netclan20241066\n",
      "Saving article for URL_ID Netclan20241067\n",
      "Saving article for URL_ID Netclan20241068\n",
      "Saving article for URL_ID Netclan20241069\n",
      "Saving article for URL_ID Netclan20241070\n",
      "Saving article for URL_ID Netclan20241071\n",
      "Saving article for URL_ID Netclan20241072\n",
      "Saving article for URL_ID Netclan20241073\n",
      "Saving article for URL_ID Netclan20241074\n",
      "Saving article for URL_ID Netclan20241075\n",
      "Saving article for URL_ID Netclan20241076\n",
      "Saving article for URL_ID Netclan20241077\n",
      "Saving article for URL_ID Netclan20241078\n",
      "Saving article for URL_ID Netclan20241079\n",
      "Saving article for URL_ID Netclan20241080\n",
      "Saving article for URL_ID Netclan20241081\n",
      "Saving article for URL_ID Netclan20241082\n",
      "Saving article for URL_ID Netclan20241083\n",
      "Saving article for URL_ID Netclan20241084\n",
      "Saving article for URL_ID Netclan20241085\n",
      "Saving article for URL_ID Netclan20241086\n",
      "Saving article for URL_ID Netclan20241087\n",
      "Saving article for URL_ID Netclan20241088\n",
      "Saving article for URL_ID Netclan20241089\n",
      "Saving article for URL_ID Netclan20241090\n",
      "Saving article for URL_ID Netclan20241091\n",
      "Saving article for URL_ID Netclan20241092\n",
      "Saving article for URL_ID Netclan20241093\n",
      "Saving article for URL_ID Netclan20241094\n",
      "Saving article for URL_ID Netclan20241095\n",
      "Saving article for URL_ID Netclan20241096\n",
      "Saving article for URL_ID Netclan20241097\n",
      "Saving article for URL_ID Netclan20241098\n",
      "Saving article for URL_ID Netclan20241099\n",
      "Saving article for URL_ID Netclan20241100\n",
      "Saving article for URL_ID Netclan20241101\n",
      "Saving article for URL_ID Netclan20241102\n",
      "Saving article for URL_ID Netclan20241103\n",
      "Saving article for URL_ID Netclan20241104\n",
      "Saving article for URL_ID Netclan20241105\n",
      "Saving article for URL_ID Netclan20241106\n",
      "Saving article for URL_ID Netclan20241107\n",
      "Saving article for URL_ID Netclan20241108\n",
      "Saving article for URL_ID Netclan20241109\n",
      "Saving article for URL_ID Netclan20241110\n",
      "Saving article for URL_ID Netclan20241111\n",
      "Saving article for URL_ID Netclan20241112\n",
      "Saving article for URL_ID Netclan20241113\n",
      "Saving article for URL_ID Netclan20241114\n",
      "Saving article for URL_ID Netclan20241115\n",
      "Saving article for URL_ID Netclan20241116\n",
      "Saving article for URL_ID Netclan20241117\n",
      "Saving article for URL_ID Netclan20241118\n",
      "Saving article for URL_ID Netclan20241119\n",
      "Saving article for URL_ID Netclan20241120\n",
      "Saving article for URL_ID Netclan20241121\n",
      "Saving article for URL_ID Netclan20241122\n",
      "Saving article for URL_ID Netclan20241123\n",
      "Saving article for URL_ID Netclan20241124\n",
      "Saving article for URL_ID Netclan20241125\n",
      "Saving article for URL_ID Netclan20241126\n",
      "Saving article for URL_ID Netclan20241127\n",
      "Saving article for URL_ID Netclan20241128\n",
      "Saving article for URL_ID Netclan20241129\n",
      "Saving article for URL_ID Netclan20241130\n",
      "Saving article for URL_ID Netclan20241131\n",
      "Saving article for URL_ID Netclan20241132\n",
      "Saving article for URL_ID Netclan20241133\n",
      "Saving article for URL_ID Netclan20241134\n",
      "Saving article for URL_ID Netclan20241135\n",
      "Saving article for URL_ID Netclan20241136\n",
      "Saving article for URL_ID Netclan20241137\n",
      "Saving article for URL_ID Netclan20241138\n",
      "Saving article for URL_ID Netclan20241139\n",
      "Saving article for URL_ID Netclan20241140\n",
      "Saving article for URL_ID Netclan20241141\n",
      "Saving article for URL_ID Netclan20241142\n",
      "Saving article for URL_ID Netclan20241143\n",
      "Saving article for URL_ID Netclan20241144\n",
      "Saving article for URL_ID Netclan20241145\n",
      "Saving article for URL_ID Netclan20241146\n",
      "Saving article for URL_ID Netclan20241147\n",
      "Saving article for URL_ID Netclan20241148\n",
      "Saving article for URL_ID Netclan20241149\n",
      "Saving article for URL_ID Netclan20241150\n",
      "Saving article for URL_ID Netclan20241151\n",
      "Saving article for URL_ID Netclan20241152\n",
      "Saving article for URL_ID Netclan20241153\n",
      "Saving article for URL_ID Netclan20241154\n",
      "Saving article for URL_ID Netclan20241155\n",
      "Saving article for URL_ID Netclan20241156\n",
      "Saving article for URL_ID Netclan20241157\n",
      "Saving article for URL_ID Netclan20241158\n",
      "Saving article for URL_ID Netclan20241159\n",
      "Saving article for URL_ID Netclan20241160\n",
      "Saving article for URL_ID Netclan20241161\n",
      "Saving article for URL_ID Netclan20241162\n",
      "Saving article for URL_ID Netclan20241163\n",
      "✅ All articles saved as <URL_ID>.txt files\n"
     ]
    }
   ],
   "source": [
    "# Create text files for each article using the same extract_article function\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    url_id = row[\"URL_ID\"]\n",
    "    url = row[\"URL\"]\n",
    "    print(f\"Saving article for URL_ID {url_id}\")\n",
    "    \n",
    "    text = extract_article(url)\n",
    "    \n",
    "    # Save the article into a text file named <URL_ID>.txt\n",
    "    filename = f\"{url_id}.txt\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text if text else \"NA\")\n",
    "\n",
    "print(\"✅ All articles saved as <URL_ID>.txt files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b351fdb3-0240-4b19-ae7e-9d5f823524d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All article text files zipped into Articles.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "# Name of the zip file\n",
    "zip_filename = \"Articles.zip\"\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, \"w\") as zipf:\n",
    "    for idx, row in df.iterrows():\n",
    "        file_name = f\"{row['URL_ID']}.txt\"\n",
    "        if os.path.exists(file_name):  # only add if the file exists\n",
    "            zipf.write(file_name)\n",
    "\n",
    "print(f\"✅ All article text files zipped into {zip_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55c0aa-ccd1-4e6b-b6f5-f1365a06b099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
